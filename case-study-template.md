# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
создал файл для анализа асимртотического анализа, первоначалные измерения показали, такую картину

Calculating -------------------------------------
    Process 0.0625Mb     16.293  (±12.3%) i/s -     80.000  in   5.026007s
     Process 0.125Mb      4.957  (±20.2%) i/s -     25.000  in   5.107268s
      Process 0.25Mb      1.379  (± 0.0%) i/s -      8.000  in   5.848466s
       Process 0.5Mb      0.283  (± 0.0%) i/s -      2.000  in   7.424395s
         Process 1Mb      0.040  (± 0.0%) i/s -      1.000  in  24.695813s

Comparison:
    Process 0.0625Mb:       16.3 i/s
     Process 0.125Mb:        5.0 i/s - 3.29x  slower
      Process 0.25Mb:        1.4 i/s - 11.81x  slower
       Process 0.5Mb:        0.3 i/s - 57.52x  slower
         Process 1Mb:        0.0 i/s - 402.36x  slower

rss after work: 124 MB
Finish in 12.45

## Massif Visualizer
График построен на исходном коде с файлом объемом 250км, пиковое потребление памяти 92.3мб
![graph](https://imgur.com/TM3Uc98)

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: *как вы построили feedback_loop*

## Вникаем в детали системы, чтобы найти 20% точек роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*

Вот какие проблемы удалось найти и решить

### Method Array.select занимает ~ 83% wall_time
Измерения: ruby-prof, режим walltime, FlatPrinter
Вывод: неопитмальный выбор типа данных
Действия: замена массива session на hash с ключом user_id
Результат:
rss after work: 38 MB
Finish in 0.26
Process 0.5Mb:        4.9 i/s

### Метод Array.each занимает 99% времени
Измерения: ruby-prof, режим walltime, GraphPrinter
Вывод: дочерние вызовы этих методов написпны не оптимально
Действия: вынос дочерних вызовов в отдельные методы, показал, что 42% занмиет вызов Array.all?,
замена на Set
Результат:
rss after work: 37 MB
Finish in 0.21
Process 0.5Mb:        6.5 i/s

### collect_stats_from_users вызывается 7 раз и занимает 62%, в нем 30% приходится на Date.parse
Измерения: ruby-prof, режим walltime, CallStackPrinter
Вывод: Выбор неоптимального метода
Действия: замена на Date.strf
Результат:
rss after work: 36 MB
Finish in 0.16
Process 0.5Mb:        9.1 i/s

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце*


*Какими ещё результами можете поделиться*

## Защита от регресса производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы сделано *то, что вы для этого сделали*
