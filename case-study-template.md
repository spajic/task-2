# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно справлялась с большими файлами за 91-92 секунды, но мы решили ее дооптимизировать.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: замер времени работы скрипта и количевсто используемой памяти.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 7 секунд обработки файла.

Вот как я построил `feedback_loop`:
1. Создал shell скрипт с тремя запусками для 50k, 100k и 200k строками из data_large файла.
2. Добавил профилеровщик памяти
3. Вносил изменения в исходный код
4. Проверял скорость работы обработки файла
5. Если скорость не менялась, переходил к шагу 3. Если ускорялось, к шагу 6.
6. Переходим к следующей точке роста.

## Вникаем в детали системы, чтобы найти 20% точек роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался ruby-prof.

Вот какие проблемы удалось найти и решить

### Ваша находка №1
Используя Callstack отчет, обнаружил, что код из задания 1 имеет точку роста(12% всего времени) в методе include? для сбора уникальных браузеров.

После рефакторинга, точка роста упала до менее 2% от всего времени.
Время работы всего срипта упало до 86 секунд.
Количество выделяемой памяти практически не поменялось.

### Ваша находка №2
Следующая точка роста была в Hash#to_json(около 14%) с Callstack отчетом:
14.02% (14.02%) JSON::Ext::Generator::GeneratorMethods::Hash#to_json [1 calls, 1 total]

Использование гема oj помогло ужать генерацию json до ~3%:
2.62% (2.62%) <Module::Oj>#dump [1 calls, 1 total]
Время работы всего срипта упало до 76-78 секунд.

### Ваша находка №3
Собрал flamegraph из rbspy. Проанализировал и понял, что callstask отчет от ruby-prof показывает тоже самое.
Но информации чуть меньше от rbspy и ruby 2.6.x не поддерживается в rbspy.

### Ваша находка №4
Около 47% всего времени занимал сбор статистики в TaskClass#collect_stats_from_users.
Повторяющиеся или похожие map методы были вынесены в общие методы, что помогло сократить все время с 47% до 33%.
Время работы всего срипта упало до 60-65 секунд.

### Ваша находка №5
При переходе на другую систему с 8 ядрами с 16 RAM. Скорость обработки файла упала сама собой до 45 секунд...
Возможно ноутбук с 4 ядрами и 8 RAM был подгружен другими процессами...

### Ваша находка №6
Upcase вызывался достаточно часто в TaskClass#parse_session:
 3.87% (29.93%) String#upcase

Было решено зарефакторить этот метод. После рефакторинга скорость оботки файла упала до 39 секунд.

### Ваша находка №7
Самую жирную точку роста в split(',') не удалось решить. split занимал 23% всего времени на конечном файле после всех изменений перечисленных выше.

## Результаты
В результате проделанной оптимизации удалось сократить время обработки файла с ~90 секунд до ~39 секунд.

## Защита от регресса производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы изменен старый юнит тест, чтобы не использовать весь файл с данными, а только маленький файл для ускорения прогона тестов. Но с погрешностью в еще 20% минуты с учетом загруженность или других факторов на системы, которые могут повлиять на скорость обработки данных.
